import streamlit as st
from groq import Groq
from gtts import gTTS
import io
import uuid
from streamlit_mic_recorder import mic_recorder

# --- 1. ‡∞™‡±á‡∞ú‡±Ä ‡∞∏‡±Ü‡∞ü‡±ç‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç‡∞∏‡±ç ---
st.set_page_config(page_title="Mitra AI - Professional", layout="wide", page_icon="üßò")

# --- 2. ‡∞á‡∞®‡∞ø‡∞∑‡∞ø‡∞Ø‡∞≤‡±à‡∞ú‡±á‡∞∑‡∞®‡±ç ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = {}  
if "current_chat_id" not in st.session_state:
    st.session_state.current_chat_id = None
if "ai_memory" not in st.session_state:
    st.session_state.ai_memory = "‡∞®‡±Ä ‡∞™‡±á‡∞∞‡±Å ‡∞Æ‡∞ø‡∞§‡±ç‡∞∞. ‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å ‡∞¨‡±ç‡∞∞‡∞π‡±ç‡∞Æ‡∞ï‡±Å‡∞Æ‡∞æ‡∞∞‡∞ø‡∞∏‡±ç ‡∞Ü‡∞ß‡±ç‡∞Ø‡∞æ‡∞§‡±ç‡∞Æ‡∞ø‡∞ï ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡∞¶‡∞∞‡±ç‡∞∂‡∞ø‡∞µ‡∞ø."

def get_groq_client():
    return Groq(api_key=st.secrets["GROQ_API_KEY"])

client = get_groq_client()

# --- 3. ‡∞∏‡±à‡∞°‡±ç ‡∞¨‡∞æ‡∞∞‡±ç (‡∞ö‡∞æ‡∞ü‡±ç ‡∞Æ‡±á‡∞®‡±á‡∞ú‡±ç‡∞Æ‡±Ü‡∞Ç‡∞ü‡±ç) ---
with st.sidebar:
    st.title("üïâÔ∏è ‡∞Æ‡∞ø‡∞§‡±ç‡∞∞ ‡∞ï‡∞Ç‡∞ü‡±ç‡∞∞‡±ã‡∞≤‡±ç‡∞∏‡±ç")
    
    if st.button("‚ûï ‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞ö‡∞æ‡∞ü‡±ç", use_container_width=True):
        new_id = str(uuid.uuid4())
        st.session_state.chat_history[new_id] = {"title": "‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£", "messages": []}
        st.session_state.current_chat_id = new_id
        st.rerun()

    st.divider()
    st.subheader("‡∞Æ‡±Ä ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£‡∞≤‡±Å")
    
    for chat_id in list(st.session_state.chat_history.keys()):
        col1, col2, col3 = st.columns([0.6, 0.2, 0.2])
        with col1:
            if st.button(st.session_state.chat_history[chat_id]["title"], key=f"btn_{chat_id}", use_container_width=True):
                st.session_state.current_chat_id = chat_id
                st.rerun()
        
        # 1. ‡∞™‡±á‡∞∞‡±Å ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡±Å‡∞ï‡±Å‡∞®‡±á ‡∞Ü‡∞™‡±ç‡∞∑‡∞®‡±ç (Rename)
        with col2:
            if st.button("‚úèÔ∏è", key=f"ren_{chat_id}"):
                st.session_state.rename_id = chat_id
        
        with col3:
            if st.button("üóëÔ∏è", key=f"del_{chat_id}"):
                del st.session_state.chat_history[chat_id]
                if st.session_state.current_chat_id == chat_id:
                    st.session_state.current_chat_id = None
                st.rerun()
        
        # ‡∞™‡±á‡∞∞‡±Å ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞¨‡∞æ‡∞ï‡±ç‡∞∏‡±ç
        if "rename_id" in st.session_state and st.session_state.rename_id == chat_id:
            new_title = st.text_input("‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞™‡±á‡∞∞‡±Å:", value=st.session_state.chat_history[chat_id]["title"], key=f"input_{chat_id}")
            if st.button("Save", key=f"save_title_{chat_id}"):
                st.session_state.chat_history[chat_id]["title"] = new_title
                del st.session_state.rename_id
                st.rerun()

    st.divider()
    with st.expander("‚öôÔ∏è ‡∞è‡∞ê ‡∞Æ‡±Ü‡∞Æ‡∞∞‡±Ä ‡∞∏‡±Ü‡∞ü‡±ç‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç‡∞∏‡±ç"):
        st.session_state.ai_memory = st.text_area("‡∞ú‡±ç‡∞û‡∞æ‡∞™‡∞ï‡∞æ‡∞≤‡±Å:", value=st.session_state.ai_memory)

# --- 4. ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç-‡∞ü‡±Å-‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç (Whisper API) ---
def speech_to_text(audio_data):
    try:
        # ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞°‡±á‡∞ü‡∞æ‡∞®‡±Å ‡∞´‡±à‡∞≤‡±ç ‡∞≤‡∞æ‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞°‡∞Ç
        audio_file = io.BytesIO(audio_data)
        audio_file.name = "audio.wav"
        
        transcription = client.audio.transcriptions.create(
            file=audio_file,
            model="whisper-large-v3", # Groq ‡∞≤‡±ã ‡∞Ö‡∞§‡±ç‡∞Ø‡∞Ç‡∞§ ‡∞µ‡±á‡∞ó‡∞µ‡∞Ç‡∞§‡∞Æ‡±à‡∞® ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞Æ‡±ã‡∞°‡∞≤‡±ç
            language="te" # ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞≠‡∞æ‡∞∑ ‡∞ï‡±ã‡∞∏‡∞Ç
        )
        return transcription.text
    except Exception as e:
        return f"‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞≤‡±ã‡∞™‡∞Ç: {e}"

# --- 5. ‡∞™‡±ç‡∞∞‡∞ß‡∞æ‡∞® ‡∞á‡∞Ç‡∞ü‡∞∞‡±ç‚Äå‡∞´‡±á‡∞∏‡±ç ---
st.header("üî± ‡∞Æ‡∞ø‡∞§‡±ç‡∞∞ - ‡∞Ü‡∞ß‡±ç‡∞Ø‡∞æ‡∞§‡±ç‡∞Æ‡∞ø‡∞ï ‡∞ú‡±ç‡∞û‡∞æ‡∞® ‡∞µ‡±á‡∞¶‡∞ø‡∞ï")

if not st.session_state.current_chat_id:
    st.info("‡∞ö‡∞æ‡∞ü‡±ç ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.")
    st.stop()

current_chat = st.session_state.chat_history[st.session_state.current_chat_id]

# ‡∞Æ‡±Ü‡∞∏‡±á‡∞ú‡±ç ‡∞π‡∞ø‡∞∏‡±ç‡∞ü‡∞∞‡±Ä ‡∞ö‡±Ç‡∞™‡∞°‡∞Ç
for idx, m in enumerate(current_chat["messages"]):
    with st.chat_message(m["role"]):
        st.markdown(m["content"])
        if m["role"] == "assistant":
            tts = gTTS(text=m["content"].replace("*",""), lang='te')
            f = io.BytesIO(); tts.write_to_fp(f)
            st.audio(f)

# --- 6. ‡∞á‡∞®‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç ‡∞∏‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç (‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç & ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç) ---
st.divider()
voice_text = ""
col_mic, col_txt = st.columns([0.1, 0.9])

with col_mic:
    # 2. ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞∞‡∞ø‡∞ï‡∞æ‡∞∞‡±ç‡∞°‡∞ø‡∞Ç‡∞ó‡±ç ‡∞´‡±Ä‡∞ö‡∞∞‡±ç ‡∞´‡∞ø‡∞ï‡±ç‡∞∏‡±ç
    audio = mic_recorder(start_prompt="üé§", stop_prompt="üî¥", key='recorder')
    if audio:
        with st.spinner("‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞®‡±Å‡∞Ç‡∞ö‡∞ø ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞Æ‡∞æ‡∞∞‡±Å‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å..."):
            voice_text = speech_to_text(audio['bytes'])

# ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞¨‡∞æ‡∞ï‡±ç‡∞∏‡±ç (‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ ‡∞µ‡∞ö‡±ç‡∞ö‡∞ø‡∞® ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞ï‡∞®‡∞ø‡∞™‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø)
user_input = st.chat_input("‡∞Æ‡±Ä ‡∞∏‡∞Ç‡∞¶‡±á‡∞π‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞Ö‡∞°‡∞ó‡∞Ç‡∞°‡∞ø...", key="main_input")

# ‡∞í‡∞ï‡∞µ‡±á‡∞≥ ‡∞µ‡∞æ‡∞Ø‡∞ø‡∞∏‡±ç ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç ‡∞â‡∞Ç‡∞ü‡±á ‡∞¶‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞µ‡∞æ‡∞°‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡∞æ‡∞Ç
final_prompt = user_input if user_input else (voice_text if voice_text else None)

if final_prompt:
    if voice_text: st.info(f"‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞ø‡∞Ç‡∞¶‡∞ø: {voice_text}")
    
    current_chat["messages"].append({"role": "user", "content": final_prompt})
    with st.chat_message("user"): st.markdown(final_prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("‡∞Æ‡∞ø‡∞§‡±ç‡∞∞ ‡∞Ü‡∞≤‡±ã‡∞ö‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞°‡±Å..."):
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "system", "content": st.session_state.ai_memory}] + current_chat["messages"]
            )
            answer = response.choices[0].message.content
            st.markdown(answer)
            current_chat["messages"].append({"role": "assistant", "content": answer})
            
            tts = gTTS(text=answer.replace("*",""), lang='te')
            f = io.BytesIO(); tts.write_to_fp(f)
            st.audio(f)
    st.rerun()
